{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install selenium\n",
        "!pip install dateparser\n",
        "!pip install XlsxWriter\n",
        "\n",
        "# Libraries\n",
        "import os\n",
        "import time\n",
        "import shutil\n",
        "import dateparser\n",
        "import xlsxwriter\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Union\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "\n",
        "# Create folders if not exists\n",
        "CWD = os.getcwd()\n",
        "temp_directory = \"temp_bddk_files\"\n",
        "directory = 'bddk_files'\n",
        "dir_list = [directory, temp_directory]\n",
        "for dir in dir_list:\n",
        "    if not os.path.exists(dir):\n",
        "        os.makedirs(dir)\n",
        "\n",
        "# Configurations\n",
        "PATH = f'{CWD}/{temp_directory}'\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "prefs = {'download.default_directory' : PATH}\n",
        "chrome_options.add_experimental_option('prefs', prefs)\n",
        "chrome_options.add_argument('--headless=new')\n",
        "chrome_options.add_argument(\"--no-sandbox\")\n",
        "chrome_options.add_argument('--disable-gpu')\n",
        "chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.88 Safari/537.36\")\n",
        "\n",
        "\n",
        "def get_date() -> list:\n",
        "  URL = 'https://www.bddk.org.tr/bultenhaftalik'\n",
        "  service = Service()\n",
        "  driver = webdriver.Chrome(service=service, options=chrome_options)\n",
        "  time.sleep(3)\n",
        "  driver.get(URL)\n",
        "  time.sleep(3)\n",
        "\n",
        "  date_list = []\n",
        "  for i in range(1,3):\n",
        "    date_str = '-'.join(map(str,[driver.find_element(\"xpath\",'//*[@id=\"Yil\"]/option[1]').text] + driver.find_element(\"xpath\",f'//*[@id=\"Donem\"]/option[{i}]').text.split(' ')[0].split('/')))\n",
        "    date = dateparser.parse(date_str)\n",
        "    date = date.strftime('%Y-%m-%d')\n",
        "    date_list.append(date)\n",
        "\n",
        "  return date_list\n",
        "\n",
        "\n",
        "def seperate_folders(keyword:str) -> None:\n",
        "    for filename in os.listdir(PATH):\n",
        "        if filename.endswith(\".xls\"):\n",
        "            folder_name = keyword\n",
        "            destination_folder = os.path.join(PATH, folder_name)\n",
        "\n",
        "            if not os.path.exists(destination_folder):\n",
        "                os.makedirs(destination_folder)\n",
        "\n",
        "            source_path = os.path.join(PATH, filename)\n",
        "            destination_path = os.path.join(destination_folder, filename)\n",
        "\n",
        "            shutil.move(source_path, destination_path)\n",
        "\n",
        "\n",
        "def scrape_data() -> None:\n",
        "    tarafDict = {\n",
        "                10001:500, 10002:501, 10008:502, 10009:503, 10010:504,\n",
        "                10003:505, 10004:506, 10005:507, 10006:508, 10007:511\n",
        "                }\n",
        "\n",
        "    tabloDict = {\n",
        "                280:'Krediler', 281:'Takipteki Alacaklar', 282:'Menkul Değerler',\n",
        "                283:'Mevduat', 284:'Diğer Bilanço Kalemleri', 285:'Bilanço Dışı İşlemler',\n",
        "                }\n",
        "\n",
        "    tarafNameDict = {\n",
        "                    500:'Sektör',\n",
        "                    501:'Mevduat',\n",
        "                    502:'MevduatKamu',\n",
        "                    503:'MevduatYabancı',\n",
        "                    504:'MevduatYerliÖzel',\n",
        "                    505:'KalkınmaVeYatırım',\n",
        "                    506:'Katılım',\n",
        "                    507:'Kamu',\n",
        "                    508:'Yabancı',\n",
        "                    511:'YerliÖzel',\n",
        "                    #512:'KalkınmaYatırım',\n",
        "                    #513:'MevduatÖzel',\n",
        "                    }\n",
        "\n",
        "    URL = 'https://www.bddk.org.tr/bultenhaftalik'\n",
        "    service = Service()\n",
        "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
        "    time.sleep(3)\n",
        "    driver.get(URL)\n",
        "    time.sleep(3)\n",
        "\n",
        "    driver.find_element(By.XPATH, '//*[@id=\"Donem\"]').click()\n",
        "    time.sleep(3)\n",
        "    driver.find_element(By.XPATH, '//*[@id=\"Donem\"]/option[3]').click()\n",
        "    time.sleep(3)\n",
        "    driver.find_element(By.XPATH, '//*[@id=\"DonemTablosu\"]/tbody/tr/td/form/div[4]/button').click()\n",
        "    time.sleep(3)\n",
        "\n",
        "    for tar_k, tar_v in tarafDict.items():\n",
        "        driver.find_element(By.XPATH, '//*[@id=\"tarafListesiItem-'+str(tar_k)+'\"]').click()\n",
        "        time.sleep(3)\n",
        "        driver.find_element(By.XPATH, '//*[@id=\"BTN\"]').click()\n",
        "\n",
        "        for tab_k, tab_v in tabloDict.items():\n",
        "            driver.find_element(By.XPATH, '//*[@id=\"tabloListesiItem-'+str(tab_k)+'\"]').click()\n",
        "            time.sleep(3)\n",
        "            driver.find_element(By.XPATH, '//*[@id=\"BTN\"]').click()\n",
        "            time.sleep(1)\n",
        "\n",
        "        seperate_folders(tarafNameDict[tar_v])\n",
        "\n",
        "    time.sleep(2)\n",
        "    driver.close()\n",
        "\n",
        "\n",
        "def remove_unnecessary_files() -> None:\n",
        "  items = os.listdir(PATH)\n",
        "  for item in items:\n",
        "      item_path = os.path.join(PATH, item)\n",
        "      if os.path.isdir(item_path):\n",
        "          pass\n",
        "      else:\n",
        "          os.remove(item_path)\n",
        "\n",
        "\n",
        "def rename_xls_files(directory:str=PATH) -> None:\n",
        "    folder_mapping = {\n",
        "      'Krediler': '1-Krediler',\n",
        "      'TakiptekiAlacaklar': '2-TakiptekiAlacaklar',\n",
        "      'MenkulDeğerler': '3-MenkulDeğerler',\n",
        "      'Mevduat': '4-Mevduat',\n",
        "      'DiğerBilan&#231;oKalemleri': '5-DiğerBilançoKalemleri',\n",
        "      'Bilan&#231;oDışıİşlemler': '6-BilançoDışıİşlemler',\n",
        "      }\n",
        "\n",
        "    for folder_name in os.listdir(directory):\n",
        "        folder_path = os.path.join(directory, folder_name)\n",
        "        if os.path.isdir(folder_path):\n",
        "            for filename in os.listdir(folder_path):\n",
        "                if filename.lower().endswith('.xls'):\n",
        "                    for key, value in folder_mapping.items():\n",
        "                        if key in filename:\n",
        "                            new_filename = filename.replace(key, value)\n",
        "                            file_path = os.path.join(folder_path, filename)\n",
        "                            new_file_path = os.path.join(folder_path, new_filename)\n",
        "                            os.rename(file_path, new_file_path)\n",
        "\n",
        "\n",
        "def create_dict() -> dict:\n",
        "  ordered_dict = {}\n",
        "  for folder in os.listdir(PATH):\n",
        "    temp_ordered_list = []\n",
        "    for files in os.listdir(os.path.join(PATH,folder)):\n",
        "      temp_ordered_list.append(files)\n",
        "      temp_ordered_list = sorted(temp_ordered_list, reverse=False)\n",
        "    ordered_dict[folder] = temp_ordered_list\n",
        "\n",
        "  return ordered_dict\n",
        "\n",
        "\n",
        "def clean_dict(dictionary:dict) -> dict:\n",
        "  cleaned_data = {}\n",
        "\n",
        "  for key, paths in dictionary.items():\n",
        "      seen_numbers = set()\n",
        "\n",
        "      cleaned_paths = []\n",
        "\n",
        "      for path in paths:\n",
        "          start_index = path.find(\"HaftalikBulten _\") + len(\"HaftalikBulten _\")\n",
        "          end_index = path.find(\"-\", start_index)\n",
        "          if end_index == -1:\n",
        "              end_index = path.find(\"_\", start_index)\n",
        "\n",
        "          number = path[start_index:end_index]\n",
        "\n",
        "          if number not in seen_numbers:\n",
        "              seen_numbers.add(number)\n",
        "              cleaned_paths.append(path)\n",
        "\n",
        "      if cleaned_paths:\n",
        "        cleaned_data[key] = cleaned_paths\n",
        "\n",
        "  return cleaned_data\n",
        "\n",
        "\n",
        "def create_dataframes_dict(cleaned_dict:dict) -> dict:\n",
        "  df_dict = {}\n",
        "\n",
        "  for k, v in cleaned_dict.items():\n",
        "      dfs = []\n",
        "      for file_path in v:\n",
        "          full_file_path = os.path.join(PATH, k, file_path)\n",
        "          data = pd.read_html(full_file_path, encoding='utf8') # thousands='.'\n",
        "          df = pd.concat(data, ignore_index=True)\n",
        "          if len(df.columns) == 5:\n",
        "              columns_with_5 = ['Index', 'Birim: Milyon TL', 'TP', 'YP', 'TOPLAM']\n",
        "              df.columns = columns_with_5\n",
        "              df = df.iloc[1:]\n",
        "              df = df.drop(columns='Index')\n",
        "          else:\n",
        "              columns_with_3 = ['Index', 'Birim: Milyon TL', 'TOPLAM']\n",
        "              df.columns = columns_with_3\n",
        "              df['TP'] = 0.0\n",
        "              df['YP'] = 0.0\n",
        "              df = df[['Index', 'Birim: Milyon TL', 'TP', 'YP', 'TOPLAM']]\n",
        "              df = df.iloc[1:]\n",
        "              df = df.drop(columns='Index')\n",
        "          dfs.append(df)\n",
        "\n",
        "      if dfs:\n",
        "          df_dict[k] = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "  result_dfs = {}\n",
        "  for k, df in df_dict.items():\n",
        "      result_dfs[k] = df.copy()\n",
        "\n",
        "  return result_dfs\n",
        "\n",
        "\n",
        "def create_excel(result_dfs:dict) -> None:\n",
        "  file_name = 'data.xlsx'\n",
        "  output_path = os.path.join(CWD,directory,file_name)\n",
        "  with pd.ExcelWriter(output_path) as writer:\n",
        "    for k, df in result_dfs.items():\n",
        "      df.to_excel(writer, sheet_name=k, index=False)\n",
        "\n",
        "\n",
        "def reformat_excel(date:str) -> None:\n",
        "  # take numbers dynamically\n",
        "  krediler = ['Krediler'] * 22\n",
        "  takipteki_alacaklar = ['Takipteki Alacaklar'] * 12\n",
        "  menkul_degerler = ['Menkul Değerler'] * 13\n",
        "  mevduat = ['Mevduat'] * 12\n",
        "  diger_bilanco_kalemleri = ['Diğer Bilanço Kalemleri'] * 15\n",
        "  bilanco_disi_islemler = ['Bilanço Dışı İşlemler'] * 4\n",
        "\n",
        "  kalem = krediler + takipteki_alacaklar + menkul_degerler + mevduat + diger_bilanco_kalemleri + bilanco_disi_islemler\n",
        "\n",
        "  start_values = {\n",
        "      'Krediler': 101,\n",
        "      'Takipteki Alacaklar': 201,\n",
        "      'Menkul Değerler': 301,\n",
        "      'Mevduat': 401,\n",
        "      'Diğer Bilanço Kalemleri': 501,\n",
        "      'Bilanço Dışı İşlemler': 601,\n",
        "  }\n",
        "\n",
        "  excel_file_path = os.path.join(CWD, directory, 'data.xlsx')\n",
        "  excel_data = pd.ExcelFile(excel_file_path)\n",
        "\n",
        "  sheet_names = excel_data.sheet_names\n",
        "\n",
        "  sheet_dataframes = {}\n",
        "\n",
        "  for sheet_name in sheet_names:\n",
        "      sheet_df = excel_data.parse(sheet_name)\n",
        "      sheet_df.insert(0, 'Taraf', sheet_name)\n",
        "      sheet_df.insert(1, 'Kalem', pd.Series(kalem))\n",
        "      sheet_df.insert(0, 'Metrik',  sheet_df.groupby('Kalem').cumcount() + sheet_df['Kalem'].map(start_values))\n",
        "      sheet_df['END_DT'] =  date\n",
        "      sheet_dataframes[sheet_name] = sheet_df\n",
        "\n",
        "  file_name = f'{date}.xlsx'\n",
        "  output_excel_path = os.path.join(CWD, directory, file_name)\n",
        "  with pd.ExcelWriter(output_excel_path) as writer:\n",
        "      for sheet_name, sheet_df in sheet_dataframes.items():\n",
        "          sheet_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
        "\n",
        "\n",
        "def create_mevduatozel_sheet(date:str) -> None:\n",
        "  file_name = f'{date}.xlsx'\n",
        "  excel_path = os.path.join(CWD, directory, file_name)\n",
        "\n",
        "  df_mevduat_yabanci = pd.read_excel(excel_path, sheet_name='MevduatYabancı')\n",
        "  df_mevduat_yerliozel = pd.read_excel(excel_path, sheet_name='MevduatYerliÖzel')\n",
        "\n",
        "  def clean_and_convert(value):\n",
        "    cleaned_value = str(value).replace('.', '').replace(',', '.')\n",
        "    return float(cleaned_value)\n",
        "\n",
        "  df_mevduat_yabanci['TP'] = df_mevduat_yabanci['TP'].apply(clean_and_convert)\n",
        "  df_mevduat_yabanci['YP'] = df_mevduat_yabanci['YP'].apply(clean_and_convert)\n",
        "  df_mevduat_yabanci['TOPLAM'] = df_mevduat_yabanci['TOPLAM'].apply(clean_and_convert)\n",
        "\n",
        "  df_mevduat_yerliozel['TP'] = df_mevduat_yerliozel['TP'].apply(clean_and_convert)\n",
        "  df_mevduat_yerliozel['YP'] = df_mevduat_yerliozel['YP'].apply(clean_and_convert)\n",
        "  df_mevduat_yerliozel['TOPLAM'] = df_mevduat_yerliozel['TOPLAM'].apply(clean_and_convert)\n",
        "\n",
        "  # create new dataframe\n",
        "  df_mevduat_ozel = pd.DataFrame(columns=df_mevduat_yabanci.columns)\n",
        "\n",
        "  # create new values with summation\n",
        "  df_mevduat_ozel['TP'] = df_mevduat_yabanci['TP'] + df_mevduat_yerliozel['TP']\n",
        "  df_mevduat_ozel['YP'] = df_mevduat_yabanci['YP'] + df_mevduat_yerliozel['YP']\n",
        "  df_mevduat_ozel['TOPLAM'] = df_mevduat_yabanci['TOPLAM'] + df_mevduat_yerliozel['TOPLAM']\n",
        "\n",
        "  # fill the missing columns\n",
        "  df_mevduat_ozel['Metrik'] = df_mevduat_yabanci['Metrik']\n",
        "  df_mevduat_ozel['Taraf'] = 'MevduatÖzel'\n",
        "  df_mevduat_ozel['Kalem'] = df_mevduat_yabanci['Kalem']\n",
        "  df_mevduat_ozel['Birim: Milyon TL'] = df_mevduat_yabanci['Birim: Milyon TL']\n",
        "  df_mevduat_ozel['END_DT'] = df_mevduat_yabanci['END_DT']\n",
        "\n",
        "  sheet_name = 'MevduatÖzel'\n",
        "  with pd.ExcelWriter(excel_path, engine='openpyxl', mode='a') as writer:\n",
        "      df_mevduat_ozel.to_excel(writer, sheet_name = sheet_name, index=False)\n",
        "\n",
        "\n",
        "def create_ozel_sheet(date:str) -> None:\n",
        "  file_name = f'{date}.xlsx'\n",
        "  excel_path = os.path.join(CWD, directory, file_name)\n",
        "\n",
        "  df_yabanci = pd.read_excel(excel_path, sheet_name='Yabancı')\n",
        "  df_yerliozel = pd.read_excel(excel_path, sheet_name='YerliÖzel')\n",
        "\n",
        "  def clean_and_convert(value):\n",
        "    cleaned_value = str(value).replace('.', '').replace(',', '.')\n",
        "    return float(cleaned_value)\n",
        "\n",
        "  df_yabanci['TP'] = df_yabanci['TP'].apply(clean_and_convert)\n",
        "  df_yabanci['YP'] = df_yabanci['YP'].apply(clean_and_convert)\n",
        "  df_yabanci['TOPLAM'] = df_yabanci['TOPLAM'].apply(clean_and_convert)\n",
        "\n",
        "  df_yerliozel['TP'] = df_yerliozel['TP'].apply(clean_and_convert)\n",
        "  df_yerliozel['YP'] = df_yerliozel['YP'].apply(clean_and_convert)\n",
        "  df_yerliozel['TOPLAM'] = df_yerliozel['TOPLAM'].apply(clean_and_convert)\n",
        "\n",
        "  # create new dataframe\n",
        "  df_ozel = pd.DataFrame(columns=df_yabanci.columns)\n",
        "\n",
        "  # create new values with summation\n",
        "  df_ozel['TP'] = df_yabanci['TP'] + df_yerliozel['TP']\n",
        "  df_ozel['YP'] = df_yabanci['YP'] + df_yerliozel['YP']\n",
        "  df_ozel['TOPLAM'] = df_yabanci['TOPLAM'] + df_yerliozel['TOPLAM']\n",
        "\n",
        "  # fill the missing columns\n",
        "  df_ozel['Metrik'] = df_yabanci['Metrik']\n",
        "  df_ozel['Taraf'] = 'Özel'\n",
        "  df_ozel['Kalem'] = df_yabanci['Kalem']\n",
        "  df_ozel['Birim: Milyon TL'] = df_yabanci['Birim: Milyon TL']\n",
        "  df_ozel['END_DT'] = df_yabanci['END_DT']\n",
        "\n",
        "  sheet_name = 'Özel'\n",
        "  with pd.ExcelWriter(excel_path, engine='openpyxl', mode='a') as writer:\n",
        "      df_ozel.to_excel(writer, sheet_name = sheet_name, index=False)\n",
        "\n",
        "\n",
        "def transform_numeric_columns(date:str) -> None:\n",
        "  def clean_and_convert(value):\n",
        "      cleaned_value = str(value).replace('.', '').replace(',', '.')\n",
        "      return float(cleaned_value)\n",
        "\n",
        "\n",
        "  excel_file_path = os.path.join(CWD, directory, f'{date}.xlsx')\n",
        "  excel_data = pd.ExcelFile(excel_file_path)\n",
        "\n",
        "  sheet_names = excel_data.sheet_names\n",
        "  sheet_dataframes = {}\n",
        "\n",
        "  for sheet_name in sheet_names:\n",
        "    sheet_df = excel_data.parse(sheet_name)\n",
        "    sheet_df['TP'] = sheet_df['TP'].apply(clean_and_convert)\n",
        "    sheet_df['YP'] = sheet_df['YP'].apply(clean_and_convert)\n",
        "    sheet_df['TOPLAM'] = sheet_df['TOPLAM'].apply(clean_and_convert)\n",
        "    sheet_dataframes[sheet_name] = sheet_df\n",
        "\n",
        "  with pd.ExcelWriter(excel_file_path) as writer:\n",
        "    for sheet_name, sheet_df in sheet_dataframes.items():\n",
        "      sheet_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
        "\n",
        "\n",
        "def create_weekly_report(date_list:list):\n",
        "  current_date, previous_date = date_list\n",
        "\n",
        "  filename_1, filename_2 = f'{current_date}.xlsx', f'{previous_date}.xlsx'\n",
        "  file_1, file_2 = os.path.join(CWD,directory,filename_1), os.path.join(CWD,directory,filename_2)\n",
        "\n",
        "  current_week_dataframes = pd.read_excel(file_2, sheet_name=None)\n",
        "  previous_week_dataframes = pd.read_excel(file_1, sheet_name=None)\n",
        "\n",
        "  columns_to_add = ['TP', 'YP', 'TOPLAM', 'END_DT']\n",
        "\n",
        "  updated_dataframes = {}\n",
        "\n",
        "  for sheet_name in previous_week_dataframes.keys():\n",
        "    previous_week_df = previous_week_dataframes[sheet_name]\n",
        "    current_week_df = current_week_dataframes[sheet_name]\n",
        "\n",
        "    current_week_selected = current_week_df[columns_to_add]\n",
        "\n",
        "    updated_df = pd.concat([previous_week_df, current_week_selected], axis=1)\n",
        "\n",
        "    updated_dataframes[sheet_name] = updated_df\n",
        "\n",
        "  file_name = 'Sektör_Haftalık_Data.xlsx'\n",
        "  with pd.ExcelWriter(os.path.join(CWD,directory,file_name)) as writer:\n",
        "      for sheet_name, updated_df in updated_dataframes.items():\n",
        "          updated_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
        "\n",
        "\n",
        "def run():\n",
        "    date_list = get_date()  # (current_date, previous_date)\n",
        "\n",
        "    for date in date_list:\n",
        "      print(f'{date} tarihli veri çekiliyor..')\n",
        "      scrape_data()\n",
        "      remove_unnecessary_files()\n",
        "      rename_xls_files()\n",
        "      ordered_dict = create_dict()\n",
        "      cleaned_dict = clean_dict(dictionary=ordered_dict)\n",
        "      result_dfs = create_dataframes_dict(cleaned_dict=cleaned_dict)\n",
        "      create_excel(result_dfs=result_dfs)\n",
        "      reformat_excel(date=date)\n",
        "      create_mevduatozel_sheet(date=date)\n",
        "      create_ozel_sheet(date=date)\n",
        "      transform_numeric_columns(date=date)\n",
        "      shutil.rmtree(PATH, ignore_errors=True)\n",
        "      print(f'{date} tarihli veri başarıyla çekildi!')\n",
        "\n",
        "    create_weekly_report(date_list=date_list)\n",
        "run()"
      ],
      "metadata": {
        "id": "IunUbso7s7EE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa1bb1c5-85b8-4772-92f0-3357bb63b650"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting selenium\n",
            "  Downloading selenium-4.11.2-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3[socks]<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from selenium) (2.0.4)\n",
            "Collecting trio~=0.17 (from selenium)\n",
            "  Downloading trio-0.22.2-py3-none-any.whl (400 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.2/400.2 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trio-websocket~=0.9 (from selenium)\n",
            "  Downloading trio_websocket-0.10.3-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=20.1.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (23.1.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (3.4)\n",
            "Collecting outcome (from trio~=0.17->selenium)\n",
            "  Downloading outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.1.3)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Collecting h11<1,>=0.9.0 (from wsproto>=0.14->trio-websocket~=0.9->selenium)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: outcome, h11, wsproto, trio, trio-websocket, selenium\n",
            "Successfully installed h11-0.14.0 outcome-1.2.0 selenium-4.11.2 trio-0.22.2 trio-websocket-0.10.3 wsproto-1.2.0\n",
            "Collecting dateparser\n",
            "  Downloading dateparser-1.1.8-py2.py3-none-any.whl (293 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.8/293.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from dateparser) (2.8.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from dateparser) (2023.3)\n",
            "Requirement already satisfied: regex!=2019.02.19,!=2021.8.27 in /usr/local/lib/python3.10/dist-packages (from dateparser) (2023.6.3)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from dateparser) (5.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil->dateparser) (1.16.0)\n",
            "Installing collected packages: dateparser\n",
            "Successfully installed dateparser-1.1.8\n",
            "Collecting XlsxWriter\n",
            "  Downloading XlsxWriter-3.1.2-py3-none-any.whl (153 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: XlsxWriter\n",
            "Successfully installed XlsxWriter-3.1.2\n",
            "2023-08-11 tarihli veri çekiliyor..\n",
            "2023-08-11 tarihli veri başarıyla çekildi!\n",
            "2023-08-04 tarihli veri çekiliyor..\n",
            "2023-08-04 tarihli veri başarıyla çekildi!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Seperate dataframes\n",
        "df_500 = weekly_df[weekly_df['TARAF'] == 'Sektör']\n",
        "df_501 = weekly_df[weekly_df['TARAF'] == 'Mevduat']\n",
        "df_506 = weekly_df[weekly_df['TARAF'] == 'Mevduat - Kamu']\n",
        "df_507 = weekly_df[weekly_df['TARAF'] == 'Mevduat - Yabancı']\n",
        "df_508 = weekly_df[weekly_df['TARAF'] == 'Mevduat - Yerli Özel']\n",
        "df_512 = weekly_df[weekly_df['TARAF'] == 'Kalkınma ve Yatırım']\n",
        "df_511 = weekly_df[weekly_df['TARAF'] == 'Katılım']\n",
        "df_502 = weekly_df[weekly_df['TARAF'] == 'Kamu']\n",
        "df_504 = weekly_df[weekly_df['TARAF'] == 'Yabancı']\n",
        "df_503 = weekly_df[weekly_df['TARAF'] == 'Yerli Özel']\n",
        "\n",
        "# df_ozel = weekly_df[weekly_df['TARAF'] == 'Özel']\n",
        "# df_mevduat_ozel = weekly_df[weekly_df['TARAF'] == 'Mevduat Özel']\n",
        "\n",
        "# Sorted Dataframe List\n",
        "dataframes = [df_500,df_501,df_502,df_503,df_504,\n",
        "           df_506,df_507,df_508,df_511,df_512]\n",
        "\n",
        "def reformat_dataframe(df:pd.DataFrame) -> pd.DataFrame:\n",
        "  # Create Missing Columns\n",
        "  df['METRIK_IZLM_DEGER'] = df['METRIK_DEGER']\n",
        "  df['IS_AKIS_NO'] = 26\n",
        "\n",
        "  # Relocate Columns with Correct Order\n",
        "  df = df[['METRIK_NO', 'END_DT', 'TL_YP_KOD', 'METRIK_DEGER', 'METRIK_IZLM_DEGER', 'BNK_KRM_KOD', 'IS_AKIS_NO']]\n",
        "\n",
        "  # Convert Datetime to Correct Format\n",
        "  df['END_DT'] = pd.to_datetime(df['END_DT'], errors='coerce')\n",
        "  df['END_DT'] = df['END_DT'].dt.strftime('%m/%d/%Y')\n",
        "\n",
        "  # Sort Values with TL_YP_KOD and METRIK_NO Columns\n",
        "  df['TL_YP_KOD'] = pd.Categorical(df['TL_YP_KOD'], ordered=True,\n",
        "                                       categories= ['T', 'Y', 'P'])\n",
        "  df = df.sort_values(by=['TL_YP_KOD','METRIK_NO'])\n",
        "  return df\n",
        "\n",
        "reformated_dataframes = []\n",
        "\n",
        "for dataframe in dataframes:\n",
        "  reformated_dataframes.append(reformat_dataframe(dataframe))\n",
        "\n",
        "df = pd.concat(dataframes)"
      ],
      "metadata": {
        "id": "CiHe-4UtVTev"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}